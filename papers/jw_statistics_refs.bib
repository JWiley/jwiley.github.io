@Article{BaronR1986,
  author = 	 {Reuben M. Baron and David A. Kenny},
  title = 	 {The Moderator-Mediator Variable Distinction in Social Psychological Research: Conceptual, Strategic, and Statistical Considerations},
  journal = 	 {Journal of Personality and Social Psychology},
  year = 	 {1986},
  volume = 	 {51},
  number = 	 {6},
  pages = 	 {1173--1182},
  OPTnote = 	 {},
  abstract = 	 {In this article, we attempt to distinguish between the properties of moderator and mediator variables at a number of levels. First, we seek to make theorists and researchers aware of the importance of not using the terms moderator and mediator interchangeably by carefully elaborating, both conceptually and strategically, the many ways in which moderators and mediators differ. We then go beyond this largely pedagogical function and delineate the conceptual and strategic implications of making use of such distinctions with regard to a wide range of phenomena, including control and stress, attitudes, and personality traits. We also provide a specific compendium of analytic procedures appropriate for making the most effective use of the moderator and mediator distinction, both separately and in terms of a broader causal system that includes both moderators and mediators.}
}

@Article{BeckerR1996,
  author = 	 {Richard A. Becker and William S. Cleveland and Ming-Jen Shyu},
  title = 	 {The Visual Design and Control of Trellis Display},
  journal = 	 {Journal of Computational and Graphical Statistics},
  year = 	 {1996},
  volume = 	 {5},
  number = 	 {2},
  pages = 	 {123--155},
  url = 	 {http://www.jstor.org/stable/1390777},
  OPTnote = 	 {},
  abstract = 	 {Trellis display is a framework for the visualization of data. Its most prominent aspect is an overall visual design, reminiscent of a garden trelliswork, in which panels are laid out into rows, columns, and pages. On each panel of the trellis, a subset of the data is graphed by a display method such as a scatterplot, curve plot, boxplot, 3-D wireframe, normal quantile plot, or dot plot. Each panel shows the relationship of certain variables conditional on the values of other variables. A number of display methods employed in the visual design of Trellis display enable it to succeed in uncovering the structure of data even when the structure is quite complicated. For example, Trellis display provides a powerful mechanismf or understandingin teractionsi n studies of how a response depends on explanatory variables. Three examples demonstrate this; in each case, we make important discoveries not appreciated in the original analyses. Several control methods are also essential to Trellis display. A control method is a technique for specifying information so that a display can be drawn. The control methods of Trellis display form a basic conceptual framework that can be used in designing software. We have demonstrated the viability of the control methods by implementing them in the S/S-PLUS system for graphics and data analysis, but they can be implemented in any software system with a basic capability for drawing graphs.}
}

@Article{ClevelandW1984a,
  author = 	 {William S. Cleveland and Robert McGill},
  title = 	 {Graphical Perception: Theory, Experimentation, and Application to the Development of Graphical Methods},
  journal = 	 {Journal of the American Statistical Association},
  year = 	 {1984},
  volume = 	 {79},
  number = 	 {387},
  pages = 	 {531--554},
  url =          {http://www.jstor.org/stable/2288400},
  OPTnote = 	 {},
  keywords =     {Computer graphics},
  keywords =     {Psychophysics},
  abstract = 	 {The subject of graphical methods for data analysis and for data presentation needs a scientific foundation. In this article we take a few steps in the direction of establishing such a foundation. Our approach is based on graphical perception-the visual decoding of information encoded on graphs-and it includes both theory and experimen- tation to test the theory. The theory deals with a small but important piece of the whole process of graphical perception. The first part is an identification of a set of elementary perceptual tasks that are carried out when people extract quantitative information from graphs. The second part is an ordering of the tasks on the basis of how accurately people perform them. Elements of the theory are tested by experimentation in which subjects record their judgments of the quantitative information on graphs. The experiments validate these elements but also suggest that the set of elementary tasks should be ex- panded. The theory provides a guideline for graph con- struction: Graphs should employ elementary tasks as high in the ordering as possible. This principle is applied to a variety of graphs, including bar charts, divided bar charts, pie charts, and statistical maps with shading. The con- clusion is that radical surgery on these popular graphs is needed, and as replacements we offer alternative graphical forms---dot charts, dot charts with grouping, and framed-rectangle charts.}
}

@Article{ClevelandW1984b,
  author = 	 {William S. Cleveland},
  title = 	 {Graphical Methods for Data Presentation: Full Scale Breaks, Dot Charts, and Multibased Logging},
  journal = 	 {The American Statistician},
  year = 	 {1984},
  volume = 	 {38},
  number = 	 {4},
  pages = 	 {270--280},
  url =          {http://www.jstor.org/stable/2683401},
  OPTnote = 	 {},
  keywords =     {Statistical graphics},
  keywords =     {Graphical perception},
  abstract = 	 {Experimentation with graphical methods for data presen- tation is important for improving graphical communication in science. Several methods---full scale breaks, dot charts, and multibased logging---are discussed. Full scale breaks are suggested as replacements for partial scale breaks, since partial breaks can fail to provide a forceful visual indication of a change in the scale. Dot charts show data that have labels and are replacements for bar charts; the new charts can be used in a wider variety of circumstances and allow more effective visual decoding of the quantitative information. Logarithms are powerful tools for data presentation; base 2 or base e is often more effective than the commonly used base 10.}
}

@Article{ClevelandW1985,
  author = 	 {William S. Cleveland and Robert McGill},
  title = 	 {Graphical Perception and Graphical Methods for Analyzing Scientific Data},
  journal = 	 {Science},
  year = 	 {1985},
  volume = 	 {229},
  number = 	 {4716},
  pages = 	 {828--833},
  url =          {http://www.jstor.org/stable/1695272},
  OPTnote = 	 {},
  abstract = 	 {}
}

@TechReport{ClevelandW1993,
  author = 	 {William S. Cleveland},
  title = 	 {A Model for Studying Display Methods of Statistical Graphics},
  institution =  {},
  year = 	 {1993},
  OPTkey = 	 {},
  OPTtype = 	 {},
  OPTnumber = 	 {},
  OPTaddress = 	 {},
  OPTmonth = 	 {October},
  OPTnote = 	 {},
  abstract = 	 {A method of statistical graphics consists of two parts: a selection of statistical information to be displayed and a selection of a visual display method to encode the information. Some display methods lead to efficient, accurate visual decoding of encoded information, and others lead to inefficient, inaccurate decoding. It is only throughrigorous studies of visual decoding that informed judgments can be made about how to chose display methods. A model has been developed to provide a framework for the study of visual decoding. The model consists of three parts: (1) a two-way classification of information on displays---quantitative-scale, quantitative-physical, categorical-scale, and categorical-physical; (2) a division of the visualprocessing of graphical displays into pattern perception and table look-up; (3) a specification of visual operations that are employed to carry out pattern perception and table look-up. Display methods are assessed by studying the visual operations to which they lead. Studies use the theory and experimental technique of various areas of vision researchincluding psychophysics, cognitive psychology, and computational vision. This process is illustrated by studies of three display methods: visual reference grids for graphs with juxtaposed panels and common scales, encoding a categorical variable on a scatterplot by the type of plotting symbol, and choosing the aspect ratio of a factor-response graph.}
}

@Book{ClevelandW1994,
  author = 	 {William S. Cleveland},
  ALTeditor = 	 {},
  title = 	 {The Elements of Graphing Data},
  publisher = 	 {Hobart Press, Summit, New Jersey},
  year = 	 {1994},
  edition = 	 {Revised},
  OPTnote = 	 {},
  ISBN = 	 {9780963488411}
}

@Article{DangT2010,
  author = 	 {Tuan Nhon Dang and Leland Wilkinson and Anushka Anand},
  title = 	 {Stacking Graphic Elements to Avoid Over-Plotting},
  journal = 	 {IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS},
  year = 	 {2010},
  volume = 	 {16},
  number = 	 {6},
  pages = 	 {1044-1052},
  month = 	 {NOVEMBER/DECEMBER},
  abstract =     {An ongoing challenge for information visualization is how to deal with over-plotting forced by ties or the relatively limited visual field of display devices. A popular solution is to represent local data density with area (bubble plots, treemaps), color (heatmaps), or aggregation (histograms, kernel densities, pixel displays). All of these methods have at least one of three deficiencies: 1) magnitude judgments are biased because area and color have convex downward perceptual functions, 2) area, hue, and brightness have relatively restricted ranges of perceptual intensity compared to length representations, and/or 3) it is difficult to brush or link to individual cases when viewing aggregations. In this paper, we introduce a new technique for visualizing and interacting with datasets that preserves density information by stacking overlapping cases. The overlapping data can be points or lines or other geometric elements, depending on the type of plot. We show real-dataset applications of this stacking paradigm and compare them to other techniques that deal with over-plotting in high-dimensional displays.}
}

@Article{HunterJ1973,
  author = 	 {John Edward Hunter},
  title = 	 {Methods of Reordering the Correlation Matrix to Facilitate Visual Inspection and Preliminary Cluster Analysis},
  journal = 	 {Journal of Educational Measurement},
  year = 	 {1973},
  volume = 	 {10},
  number = 	 {1},
  pages = 	 {51--61},
  url =          {http://www.jstor.org/stable/1433941},
  OPTnote = 	 {},
  abstract = 	 {Using the notion of parallel items this paper presents a family of new criteria for cluster analysis. Instead of looking at the item correlation matrix one could look at a matrix of similarity coefficients. These coefficients are standardized raw dot products of columns in the correlation matrix or related numbers. After discussing the properties of this matrix the discussion will move to a classic example of a factor analytic problem in personality assessment, an item pool concerned with Fromm's marketing orientation, and a brief discussion of problems outside of cluster analysis will conclude the paper.}
}

@Article{HyndmanR1996,
  author = 	 {Rob J. Hyndman and Yanan Fan},
  title = 	 {Sample Quantiles in Statistical Packages},
  journal = 	 {The American Statistician},
  year = 	 {1996},
  volume = 	 {50},
  number = 	 {4},
  pages = 	 {361 - 365},
  month = 	 {November},
  url = 	 {http://www.jstor.org/stable/2684934}
}

@TechReport{LenthR2007,
  author = 	 {Russell V. Lenth},
  title = 	 {Post Hoc Power: Tables and Commentary},
  institution =  {The University of Iowa},
  year = 	 {2007},
  number = 	 {Technical Report No. 378},
  note = 	 {A nice discussion of why post hoc power has little (if any) value.},
  abstract = 	 {Post hoc power is the retrospective power of an observed effect based on the sample size and parameter estimates derived from a given data set. Many scientists recommend using post hoc power as a follow-up analysis, especially if a finding is nonsignificant. This article presents tables of post hoc power for common t and F tests. These tables make it explicitly clear that for a given significance level, post hoc power depends only on the P value and the degrees of freedom. It is hoped that this article will lead to greater understanding of what post hoc power is--and is not. We also present a ``grand unified formula'' for post hoc power based on a reformulation of the problem, and a discussion of alternative views.}
}

@Article{McNeilD1992,
  author = 	 {Don McNeil},
  title = 	 {On Graphing Paired Data},
  journal = 	 {The American Statistician},
  year = 	 {1992},
  volume = 	 {46},
  number = 	 {4},
  pages = 	 {307--311},
  month = 	 {November},
  url =          {http://www.jstor.org/stable/2685323},
  OPTnote = 	 {},
  abstract = 	 {Techniques for graphing paired data are considered. A conventional method frequently used when reporting scientific results, particularly in medical journals, involves representing pairs of measurements by straight line segments titled at different angles related to the differences between the components of the data pairs. However when the sample size is only moderately large, this type of display can become cluttered and thus uninformative due to overlap. It is suggested that a new graph that combines features of ANOVA plots and multivalued dot charts may provide a more effective visual display of paired data. A designed experiment in data perception using simulated data provides some evidence in favor of this parallel line plot.}
}

@Article{RaoC1971a,
  title =        {Estimation of variance and covariance components--MINQUE theory},
  journal =      {Journal of Multivariate Analysis},
  volume =       {1},
  number =       {3},
  pages =        {257 - 275},
  year =         {1971},
  issn =         {0047-259X},
  doi =          {DOI: 10.1016/0047-259X(71)90001-7},
  url =          {http://www.sciencedirect.com/science/article/B6WK9-4CTN96K-JC/2/17e6b51a797393d7fc1599a0bf816a7b},
  author =       {C. Radhakrishna Rao},
  keywords =     {Estimation},
  keywords =     {variance components},
  keywords =     {covariance components},
  keywords =     {MINQUE theory}
}

@article{RaoC1971b,
  title =        {Minimum variance quadratic unbiased estimation of variance components},
  journal =      {Journal of Multivariate Analysis},
  volume =       {1},
  number =       {4},
  pages =        {445 - 456},
  year =         {1971},
  issn =         {0047-259X},
  doi =          {DOI: 10.1016/0047-259X(71)90019-4},
  url =          {http://www.sciencedirect.com/science/article/B6WK9-4CTN92K-HF/2/16e247b2521cfde925b923d53526c362},
  author =       {C. Radhakrishna Rao},
  keywords =     {Estimation},
  keywords =     {variance components},
  keywords =     {minimum variance},
  keywords =     {minimum mean square unbiased}
}

@Article{SasieniP1996,
  author = 	 {Peter D. Sasieni and Patrick Royston},
  title = 	 {Dotplots},
  journal = 	 {Journal of the Royal Statistical Society},
  year = 	 {1996},
  volume = 	 {45},
  number = 	 {2},
  pages = 	 {219--234},
  url = 	 {http://www.jstor.org/stable/2986156},
  OPTnote = 	 {},
  abstract = 	 {The dotplot is a graphical display that has features in common with the histogram and the scatterplot. Although in common use in scientific joumals, it has received scant attention in the statistical literature. We describe the basic dotplot and possible enhancements. We discuss the types of data phenomena that it is suited to detect or represent, compare it with other techniques and give a range of examples. We discuss computational issues and give code fragments in Fortran that may form the basis of a dotplot program. Such software could replace the artists' drawings that frequently appear in journals and could encourage the use of dotplots in exploratory analysis.}
}

@Article{SwayneD1998,
  author = 	 {Deborah F. Swayne and Dianne Cook and Andreas Buja},
  title = 	 {XGobi: Interactive Dynamic Data Visualization in the X Window System},
  journal = 	 {Journal of Computational and Graphical Statistics},
  year = 	 {1998},
  volume = 	 {7},
  number = 	 {1},
  pages = 	 {113--130},
  url = 	 {http://www.jstor.org/stable/1390772},
  OPTnote = 	 {},
  abstract = 	 {XGobi is a data visualization system with state-of-the-art interactive and dynamic methods for the manipulation of views of data. It implements 2-D displays of projections of points and lines in high-dimensional spaces, as well as parallel coordinate displays and textual views thereof. Projection tools include dotplots of single variables, plots of pairs of variables, 3-D data rotations, various grand tours, and interactive projection pursuit. Views of the data can be reshaped. Points can be labeled and brushed with glyphs and colors. Lines can be edited and colored. Several XGobi processes can be run simultaneously and linked for labeling, brushing, and sharing of projections. Missing data are accommodated and their patterns can be examined; multiple imputations can be given to XGobi for rapid visual diagnostics. XGobi includes an extensive online help facility. XGobi can be integrated in other software systems, as has been done for the data analysis language S, the geographic informations ystem (GIS) ArcViewTM, and the interactive multidimensional scaling program XGvis. XGobi is implemented in the X Window SystemTM for portability as well as the ability to run across a network.}
}

@Article{WainerH1981,
  author = 	 {Howard Wainer and David Thissen},
  title = 	 {Graphical Data Analysis},
  journal = 	 {Annual Review of Psychology},
  year = 	 {1981},
  volume = 	 {32},
  pages = 	 {191--241},
  OPTnote = 	 {},
}

@Article{WainerH1984,
  author = 	 {Howard Wainer},
  title = 	 {How to Display Data Badly},
  journal = 	 {The American Statistician},
  year = 	 {1984},
  volume = 	 {38},
  number = 	 {2},
  pages = 	 {137--147},
  url = 	 {http://www.jstor.org/stable/2683253},
  OPTnote = 	 {},
  abstract = 	 {Methods for displaying data badly have been devel- oping for many years, and a wide variety of interesting and inventive schemes have emerged. Presented here is a synthesis yielding the 12 most powerful techniques that seem to underlie many of the realizations found in practice. These 12 (the dirty dozen) are identified and illustrated.}
}

@Article{WilkinsonL1999,
  author = 	 {Leland Wilkinson},
  title = 	 {Dot Plots},
  journal = 	 {The American Statistician},
  year = 	 {1999},
  volume = 	 {53},
  number = 	 {3},
  pages = 	 {276-281},
  month = 	 {August},
  url = 	 {http://www.jstor.org/stable/2686111}
}

@Manual{R,
  title =        {R: A Language and Environment for Statistical Computing},
  author =       {{R Development Core Team}},
  organization = {R Foundation for Statistical Computing},
  address =      {Vienna, Austria},
  year =         {2011},
  note =         {{ISBN} 3-900051-07-0},
  url =          {http://www.R-project.org/},
}

@Book{SarkarD2008,
  title =        {Lattice: Multivariate Data Visualization with R},
  author =       {Deepayan Sarkar},
  publisher =    {Springer},
  address =      {New York},
  year =         {2008},
  note =         {ISBN 978-0-387-75968-5},
  url =          {http://lmdvr.r-forge.r-project.org},
}

@Book{WickhamH2009,
  author =       {Hadley Wickham},
  title =        {ggplot2: elegant graphics for data analysis},
  publisher =    {Springer New York},
  year =         {2009},
  isbn =         {978-0-387-98140-6},
  url =          {http://had.co.nz/ggplot2/book},
}

@Manual{WileyJ2011,
  title =        {Jmisc: A collection of miscellaneous functions},
  author =       {Joshua Wiley},
  year =         {2011},
  note =         {R package version 0.2-03},
  url =          {http://joshuawiley.com/R.aspx},
}


